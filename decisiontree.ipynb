{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find label for a value\n",
    "#if MIN_Value <=val < (m + Mean_Value) / 2 then it is assigned label a\n",
    "#if (m + Mean_Value) <=val < Mean_Value then it is assigned label b\n",
    "#if (Mean_Value) <=val < (Mean_Value + MAX_Value)/2 then it is assigned label c\n",
    "#if (Mean_Value + MAX_Value)/2 <=val <= MAX_Value  then it is assigned label d\n",
    "\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a, b, c, d\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>sl_labeled</th>\n",
       "      <th>sw_labeled</th>\n",
       "      <th>pl_labeled</th>\n",
       "      <th>pw_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sl   sw   pl   pw sl_labeled sw_labeled pl_labeled pw_labeled\n",
       "0    5.1  3.5  1.4  0.2          b          c          a          a\n",
       "1    4.9  3.0  1.4  0.2          a          b          a          a\n",
       "2    4.7  3.2  1.3  0.2          a          c          a          a\n",
       "3    4.6  3.1  1.5  0.2          a          c          a          a\n",
       "4    5.0  3.6  1.4  0.2          a          c          a          a\n",
       "..   ...  ...  ...  ...        ...        ...        ...        ...\n",
       "145  6.7  3.0  5.2  2.3          c          b          c          d\n",
       "146  6.3  2.5  5.0  1.9          c          a          c          d\n",
       "147  6.5  3.0  5.2  2.0          c          b          c          d\n",
       "148  6.2  3.4  5.4  2.3          c          c          d          d\n",
       "149  5.9  3.0  5.1  1.8          c          b          c          c\n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert all columns to labelled data\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd'}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['sl_labeled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    total = len(y)\n",
    "    entropy = 0\n",
    "    \n",
    "    for i in set(y[0]):\n",
    "        count_of_class = len(y[y[0] == i])  # counting occurence of 1 label in Y data \n",
    "        prob = count_of_class/total     # finding probability\n",
    "        entropy += prob * math.log(prob, 2)  # adding it to total entropy\n",
    "    entropy = -entropy\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_info_gain(x, y, feature) :\n",
    "    \n",
    "    parent_entropy = entropy(y)  # calculating entropy of Y \n",
    "    total_ele = len(y)   # to get the count of number of labels present in Y data\n",
    "    weighted_entropy = 0  # initiating weighted average = 0 \n",
    "    \n",
    "    val = set(x[feature])  # taking in account each unique label\n",
    "    \n",
    "    # iterating to get weighted entropies of each child and add them \n",
    "    for i in val :\n",
    "        child = y[(x[feature] == i)]\n",
    "        i_entropy = entropy(child)\n",
    "        \n",
    "        weighted_entropy += (i_entropy * len(child)) / total_ele\n",
    "        \n",
    "    #finding info gain\n",
    "    info_gain = parent_entropy - weighted_entropy  \n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Info. Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding split info these two will help us in calculating gain ratio \n",
    "def split_information(x, y, feature) :\n",
    "    total_ele = len(y)\n",
    "    weighted_avg = 0\n",
    "    val = set(x[feature]) # unique values in each feature\n",
    "    \n",
    "    for i in val : # taking 1 child at a time \n",
    "        \n",
    "        child = y[x[feature] == i] # taking values of Y where feature is i \n",
    "                \n",
    "        weighted_avg += (len(child) / total_ele) * math.log((len(child) / total_ele), 2) ## calculating weighted average here\n",
    "        \n",
    "    return -1 * weighted_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best feature and maximum Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature(x, y , features) :\n",
    "    best_feature = ''  # initiating best_feature as \" \"\n",
    "    max_gain = -1  # initiating max_gain as -1\n",
    "    \n",
    "    # traversing all features\n",
    "    for i in features :\n",
    "        \n",
    "        # finding split info and info_gain by calling these functions\n",
    "        split_info = split_information(x, y, i)\n",
    "        info_gain = find_info_gain(x, y, i)\n",
    "        \n",
    "        if split_info != 0 :\n",
    "            gain_ratio = info_gain / split_info\n",
    "            \n",
    "        else :\n",
    "            gain_ratio = -1\n",
    "        \n",
    "        # getting best feature and best gain ratio\n",
    "        if gain_ratio > max_gain :\n",
    "            best_feature = i\n",
    "            max_gain = gain_ratio\n",
    "            \n",
    "    return best_feature, max_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_T(X,Y,features,level):     # this function is base function for Decision Tree \n",
    "    classes=set(Y[0])               # take all the unique labels present in Y \n",
    "    \n",
    "    # now we will see all the cases and find out whether we can split our tree or not and whether the node is leaf or not \n",
    "    # case 1 \n",
    "    if (len(classes) == 1):     # see if the length of classes is 1 or not \n",
    "        \n",
    "            \n",
    "        print(\"Level \",level)   # now we will print the current level as we don't have further classes we've reached the leaf node \n",
    "        current_class = list(classes)[0]    # current class will be our class at 0th position (although length is 1 but we are doing this to select the class) \n",
    "        \n",
    "        print(\"Count of \",current_class,\" = \",len(Y))     # now we are printing the class and its count \n",
    "        print(\"Current Entropy is = 0.0\")                 # Entropy is 0 as class will be pure and hence no randomness \n",
    "        print(\"Reached leaf Node\")                        # we have only 1 class so we are at leaf node  \n",
    "        print(\"Output Class Name =\", current_class)\n",
    "        print()\n",
    "        return\n",
    "   \n",
    "    # case 2\n",
    "    elif len(features)==0:                                 # checking if the count of features is 0 or not                           \n",
    "        print(\"Level  \",level)                             # if feature is 0 that means we can't split further so we are just printing the level \n",
    "        \n",
    "        #finding count of each output class\n",
    "        for current_class in classes:\n",
    "            count_of_current_class = (Y[0] == current_class).sum() \n",
    "            print(\"Count of \",current_class,\" = \",count_of_current_class) \n",
    "            \n",
    "        #printing as we did in above case and it can be understood easily what we are doing \n",
    "        entropy_current = entropy(Y)\n",
    "        \n",
    "        print(\"Current Entropy is = \",entropy_current)\n",
    "        print(\"No more features left\")\n",
    "        print(\"Reached leaf Node\")\n",
    "        print(\"Output Class Name =\", current_class)\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    # case 3 when we don't have a leaf node and feature count is not 0 and count of classes is not 1 \n",
    "    else:\n",
    "        print(\"Level \",level)        # printing the current level \n",
    "        \n",
    "        max_count = 0\n",
    "        for i in classes:            # iterating over classes that is labels in Y \n",
    "            j = (Y[0]==i).sum()         # taking sum of all the ith label in Y data that is calculating its count (in Y )\n",
    "            print(\"Count of \",i,\" = \",j)       # printing the class and its count \n",
    "            \n",
    "            if j >= max_count :\n",
    "                max_count = j\n",
    "                output_class  = i\n",
    "                \n",
    "        #entropy of Current Node\n",
    "        print(\"Current Entropy is =\",entropy(Y))\n",
    "        \n",
    "        #getting best feature to split and its gain ratio\n",
    "        best_feature,gain_ratio = find_best_feature(X,Y,features)\n",
    "        print(\"Splitting on feature \",best_feature,\"with gain ratio :\",gain_ratio)\n",
    "        print(\"Output Class Name =\", output_class)\n",
    "        print()\n",
    "        \n",
    "        #splitting current node on all different values the best feature can have and recursively calling DT on each split\n",
    "        diff_val_of_best_feat = set(X[best_feature]) # get different values of the BEST Feature in current data\n",
    "        \n",
    "        #traverse each feature value , split on each \n",
    "        for current in diff_val_of_best_feat:\n",
    "            \n",
    "            x=X[(X[best_feature] == current)]\n",
    "            y=Y[(X[best_feature] == current)]\n",
    "\n",
    "            # also we are deleting features when a split has been called on it \n",
    "            #recursion\n",
    "            remaining_features = features - {best_feature}\n",
    "            \n",
    "            D_T(x,y,remaining_features,level+1)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "Count of  setosa  =  50\n",
      "Count of  versicolor  =  50\n",
      "Count of  virginica  =  50\n",
      "Current Entropy is = 1.584962500721156\n",
      "Splitting on feature  pw_labeled with gain ratio : 0.699638203622209\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  40\n",
      "Count of  virginica  =  16\n",
      "Current Entropy is = 0.863120568566631\n",
      "Splitting on feature  pl_labeled with gain ratio : 0.4334099495621066\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  39\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.6581912658132185\n",
      "Splitting on feature  sl_labeled with gain ratio : 0.12674503775809332\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  23\n",
      "Count of  virginica  =  7\n",
      "Current Entropy is = 0.783776947484701\n",
      "Splitting on feature  sw_labeled with gain ratio : 0.07092036405148876\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  14\n",
      "Count of  virginica  =  6\n",
      "Current Entropy is =  0.8812908992306927\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level   4\n",
      "Count of  versicolor  =  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is =  0.8112781244591328\n",
      "No more features left\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  14\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  3\n",
      "Count of  virginica  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  virginica  =  8\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  virginica  =  34\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = virginica\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  10\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = versicolor\n",
      "\n",
      "Level  1\n",
      "Count of  setosa  =  50\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "Output Class Name = setosa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = pd.DataFrame(iris.target)\n",
    "y[y[0] == 0] = 'setosa'\n",
    "y[y[0] == 1] = 'versicolor'\n",
    "y[y[0] == 2] = 'virginica'\n",
    "unused_features = set(df.columns)\n",
    "build_tree(df, y, unused_features, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
